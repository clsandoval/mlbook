{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import tensorflow as tf\r\n",
    "import tensorflow.keras as keras\r\n",
    "import numpy as np\r\n",
    "from sklearn.datasets import load_sample_image\r\n",
    "\r\n",
    "china = load_sample_image(\"china.jpg\")/255\r\n",
    "flower = load_sample_image(\"flower.jpg\")/255\r\n",
    "images = np.array([china,flower])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "class ResidualUnit(keras.layers.Layer):\r\n",
    "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\r\n",
    "        super().__init__(**kwargs)\r\n",
    "        self.activation = keras.activations.get(activation)\r\n",
    "        self.main_layers = [\r\n",
    "            keras.layers.Conv2D(filters,3,strides, padding='same', use_bias=False),\r\n",
    "            keras.layers.BatchNormalization(),\r\n",
    "            self.activation,\r\n",
    "            keras.layers.Conv2D(filters,3,1,padding='same', use_bias=False),\r\n",
    "            keras.layers.BatchNormalization(),\r\n",
    "        ]\r\n",
    "        self.skip_layers = []\r\n",
    "        if strides > 1:\r\n",
    "            self.skip_layers = [\r\n",
    "                keras.layers.Conv2D(filters,1, strides,padding='same', use_bias=False),\r\n",
    "                keras.layers.BatchNormalization()\r\n",
    "            ]\r\n",
    "def call(self, inputs):\r\n",
    "    Z = inputs\r\n",
    "    for layer in self.main_layers:\r\n",
    "        Z = layer(Z)\r\n",
    "        skip_Z = inputs\r\n",
    "    for layer in self.skip_layers:\r\n",
    "        skip_Z = layer(skip_Z)\r\n",
    "    return self.activation(Z + skip_Z)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "model = keras.models.Sequential()\r\n",
    "model.add(keras.layers.Conv2D(64,7,2,input_shape=[224,224,3],padding='same'))\r\n",
    "model.add(keras.layers.BatchNormalization())\r\n",
    "model.add(keras.layers.ReLU()),\r\n",
    "model.add(keras.layers.MaxPool2D(pool_size=3,strides=2,padding='same'))\r\n",
    "prev = 64\r\n",
    "for i in [64,64,64,128,128,128,128,256,256,256,256,512,512,512]:\r\n",
    "    strides = 1 if prev == i else 2\r\n",
    "    model.add(ResidualUnit(i,strides,keras.layers.ReLU()))\r\n",
    "    prev = i\r\n",
    "model.add(keras.layers.GlobalAvgPool2D())\r\n",
    "model.add(keras.layers.Flatten())   \r\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import tensorflow_datasets as tfds\r\n",
    "dataset, info = tfds.load(\"tf_flowers\", as_supervised=True, with_info=True)\r\n",
    "dataset_size = info.splits['train'].num_examples\r\n",
    "class_names = info.features['label'].names\r\n",
    "n_classes = info.features['label'].num_classes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "test_set_raw, valid_set_raw, train_set_raw = tfds.load(\r\n",
    "    \"tf_flowers\",\r\n",
    "    split=[\"train[:10%]\", \"train[10%:25%]\", \"train[25%:]\"],\r\n",
    "    as_supervised=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def preprocess(image,label):\r\n",
    "    resized_image = tf.image.resize(image, [224,224])\r\n",
    "    final_image = keras.applications.xception.preprocess_input(resized_image)\r\n",
    "    return final_image, label\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "train_set.shuffle(1000)\r\n",
    "train_set = train_set_raw.map(preprocess).batch(32).repeat().prefetch(1)\r\n",
    "valid_set = valid_set_raw.map(preprocess).batch(32).repeat().prefetch(1)\r\n",
    "test_set = test_set_raw.map(preprocess).batch(32).repeat().prefetch(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\r\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\r\n",
    "output = keras.layers.Dense(n_classes, activation='softmax')(avg)\r\n",
    "model = keras.Model(inputs=base_model.input, outputs=output)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "for layer in base_model.layers:\r\n",
    "    layer.trainable=False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.2, momentum=0.9, decay=0.01)\r\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer = optimizer, metrics=[\"accuracy\"])\r\n",
    "history = model.fit(train_set,steps_per_epoch=int(0.75 * dataset_size / 32), validation_data = valid_set,validation_steps=int(0.15 * dataset_size / 32), epochs=5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "86/86 [==============================] - 240s 3s/step - loss: 1.1728 - accuracy: 0.8045 - val_loss: 0.8381 - val_accuracy: 0.8382\n",
      "Epoch 2/5\n",
      " 5/86 [>.............................] - ETA: 3:01 - loss: 0.5420 - accuracy: 0.9125"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-7765223b70c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.75\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdataset_size\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.15\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdataset_size\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\r\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\r\n",
    "class_output = keras.layers.Dense(n_classes, activation='softmax')(avg)\r\n",
    "loc_output = keras.layers.Dense(4)(avg)\r\n",
    "model = keras.Model(inputs=base_model.input, outputs=[class_output, loc_output])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "model.compile(loss=[\"sparse_categorical_entropy\", \"mse\"], optimizer = optimizer, metrics=[\"accuracy\"])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1b532751c64f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sparse_categorical_entropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mse\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MNIST from scratch try Resnet Senet Fully convolutional net, pooling, lrn, etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "(X_train,y_train),(X_test,y_test) = keras.datasets.fashion_mnist.load_data()\r\n",
    "X_train = X_train.reshape(X_train.shape[0], 28,28,1).astype(np.float32)\r\n",
    "X_test = X_test.reshape(X_test.shape[0], 28,28,1).astype(np.float32)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "X_train = X_train/255\r\n",
    "X_test = X_test/255"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "model = keras.models.Sequential([\r\n",
    "    keras.layers.Conv2D(64,7,2,padding='same'),\r\n",
    "    keras.layers.BatchNormalization(),\r\n",
    "    keras.layers.ReLU(),\r\n",
    "    keras.layers.MaxPool2D(pool_size=3,strides=2,padding='same'),\r\n",
    "    ResidualUnit(64,1,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(64,1,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(64,1,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(128,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(128,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(128,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(128,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(256,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(256,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(256,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(256,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(256,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(256,2,keras.layers.ReLU()),\r\n",
    "    keras.layers.GlobalAvgPool2D(),\r\n",
    "    keras.layers.Flatten(),\r\n",
    "    keras.layers.Dense(10,activation=\"softmax\")\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = keras.optimizers.Adam(learning_rate = 0.001), metrics = ['accuracy'])\r\n",
    "model.fit(X_train,y_train,epochs=1000,validation_data = (X_test,y_test),batch_size=32, steps_per_epoch=60000//32)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/1000\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 1.0793 - accuracy: 0.6625 - val_loss: 0.9506 - val_accuracy: 0.6612\n",
      "Epoch 2/1000\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.7855 - accuracy: 0.7363 - val_loss: 0.7828 - val_accuracy: 0.7404\n",
      "Epoch 3/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6999 - accuracy: 0.7600 - val_loss: 0.8075 - val_accuracy: 0.7229\n",
      "Epoch 4/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6600 - accuracy: 0.7721 - val_loss: 0.7597 - val_accuracy: 0.7182\n",
      "Epoch 5/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6280 - accuracy: 0.7823 - val_loss: 0.9431 - val_accuracy: 0.6587\n",
      "Epoch 6/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6070 - accuracy: 0.7904 - val_loss: 0.7460 - val_accuracy: 0.7089\n",
      "Epoch 7/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5865 - accuracy: 0.7979 - val_loss: 0.7158 - val_accuracy: 0.7495\n",
      "Epoch 8/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5739 - accuracy: 0.8002 - val_loss: 0.7942 - val_accuracy: 0.7411\n",
      "Epoch 9/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5620 - accuracy: 0.8047 - val_loss: 0.7079 - val_accuracy: 0.7556\n",
      "Epoch 10/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5527 - accuracy: 0.8069 - val_loss: 0.8291 - val_accuracy: 0.6938\n",
      "Epoch 11/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5432 - accuracy: 0.8102 - val_loss: 0.9026 - val_accuracy: 0.6940\n",
      "Epoch 12/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5366 - accuracy: 0.8111 - val_loss: 0.6315 - val_accuracy: 0.7751\n",
      "Epoch 13/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5283 - accuracy: 0.8154 - val_loss: 0.7429 - val_accuracy: 0.7370\n",
      "Epoch 14/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5228 - accuracy: 0.8160 - val_loss: 0.7697 - val_accuracy: 0.7107\n",
      "Epoch 15/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5163 - accuracy: 0.8202 - val_loss: 0.5836 - val_accuracy: 0.7952\n",
      "Epoch 16/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5100 - accuracy: 0.8218 - val_loss: 0.7184 - val_accuracy: 0.7478\n",
      "Epoch 17/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5070 - accuracy: 0.8223 - val_loss: 0.6680 - val_accuracy: 0.7699\n",
      "Epoch 18/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5002 - accuracy: 0.8240 - val_loss: 0.6022 - val_accuracy: 0.7912\n",
      "Epoch 19/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4974 - accuracy: 0.8257 - val_loss: 0.6198 - val_accuracy: 0.7794\n",
      "Epoch 20/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4890 - accuracy: 0.8297 - val_loss: 0.5070 - val_accuracy: 0.8191\n",
      "Epoch 21/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4897 - accuracy: 0.8283 - val_loss: 0.7535 - val_accuracy: 0.7500\n",
      "Epoch 22/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4834 - accuracy: 0.8306 - val_loss: 0.6037 - val_accuracy: 0.7831\n",
      "Epoch 23/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4811 - accuracy: 0.8317 - val_loss: 0.5244 - val_accuracy: 0.8136\n",
      "Epoch 24/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4776 - accuracy: 0.8330 - val_loss: 0.5309 - val_accuracy: 0.8074\n",
      "Epoch 25/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4743 - accuracy: 0.8345 - val_loss: 0.5213 - val_accuracy: 0.8193\n",
      "Epoch 26/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4707 - accuracy: 0.8334 - val_loss: 0.6687 - val_accuracy: 0.7704\n",
      "Epoch 27/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4720 - accuracy: 0.8329 - val_loss: 0.5396 - val_accuracy: 0.8095\n",
      "Epoch 28/1000\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4673 - accuracy: 0.8353 - val_loss: 0.6552 - val_accuracy: 0.7610\n",
      "Epoch 29/1000\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4641 - accuracy: 0.8361 - val_loss: 0.6950 - val_accuracy: 0.7761\n",
      "Epoch 30/1000\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4613 - accuracy: 0.8378 - val_loss: 0.5415 - val_accuracy: 0.8102\n",
      "Epoch 31/1000\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4604 - accuracy: 0.8378 - val_loss: 0.5859 - val_accuracy: 0.7862\n",
      "Epoch 32/1000\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4561 - accuracy: 0.8398 - val_loss: 0.5292 - val_accuracy: 0.8186\n",
      "Epoch 33/1000\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4517 - accuracy: 0.8409 - val_loss: 0.5229 - val_accuracy: 0.8088\n",
      "Epoch 34/1000\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4528 - accuracy: 0.8425 - val_loss: 0.5500 - val_accuracy: 0.8123\n",
      "Epoch 35/1000\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4522 - accuracy: 0.8409 - val_loss: 0.5424 - val_accuracy: 0.8127\n",
      "Epoch 36/1000\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4474 - accuracy: 0.8429 - val_loss: 0.5705 - val_accuracy: 0.7960\n",
      "Epoch 37/1000\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4459 - accuracy: 0.8422 - val_loss: 0.5679 - val_accuracy: 0.8056\n",
      "Epoch 38/1000\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.4430 - accuracy: 0.8447 - val_loss: 0.5577 - val_accuracy: 0.8110\n",
      "Epoch 39/1000\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.4422 - accuracy: 0.8458 - val_loss: 0.7110 - val_accuracy: 0.7553\n",
      "Epoch 40/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4420 - accuracy: 0.8448 - val_loss: 0.4836 - val_accuracy: 0.8347\n",
      "Epoch 41/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4379 - accuracy: 0.8467 - val_loss: 0.5655 - val_accuracy: 0.7971\n",
      "Epoch 42/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4351 - accuracy: 0.8479 - val_loss: 0.5833 - val_accuracy: 0.7931\n",
      "Epoch 43/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4331 - accuracy: 0.8465 - val_loss: 0.4932 - val_accuracy: 0.8280\n",
      "Epoch 44/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4336 - accuracy: 0.8467 - val_loss: 0.5360 - val_accuracy: 0.8100\n",
      "Epoch 45/1000\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.4311 - accuracy: 0.8475 - val_loss: 0.4855 - val_accuracy: 0.8294\n",
      "Epoch 46/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4300 - accuracy: 0.8489 - val_loss: 0.7923 - val_accuracy: 0.7352\n",
      "Epoch 47/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4293 - accuracy: 0.8493 - val_loss: 0.4671 - val_accuracy: 0.8374\n",
      "Epoch 48/1000\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4284 - accuracy: 0.8489 - val_loss: 0.5764 - val_accuracy: 0.8002\n",
      "Epoch 49/1000\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.4274 - accuracy: 0.8496 - val_loss: 0.5160 - val_accuracy: 0.8233\n",
      "Epoch 50/1000\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.4259 - accuracy: 0.8500 - val_loss: 0.6435 - val_accuracy: 0.7852\n",
      "Epoch 51/1000\n",
      " 979/1875 [==============>...............] - ETA: 8s - loss: 0.4228 - accuracy: 0.8508"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-4bbc5b4cea9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60000\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "464a224b326fd00042ecfc16c55fb6849077c393f04f27045b762af6d5e516e1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}