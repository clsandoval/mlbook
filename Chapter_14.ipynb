{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import tensorflow as tf\r\n",
    "import tensorflow.keras as keras\r\n",
    "import numpy as np\r\n",
    "from sklearn.datasets import load_sample_image\r\n",
    "\r\n",
    "china = load_sample_image(\"china.jpg\")/255\r\n",
    "flower = load_sample_image(\"flower.jpg\")/255\r\n",
    "images = np.array([china,flower])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "class ResidualUnit(keras.layers.Layer):\r\n",
    "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\r\n",
    "        super().__init__(**kwargs)\r\n",
    "        self.activation = keras.activations.get(activation)\r\n",
    "        self.main_layers = [\r\n",
    "            keras.layers.Conv2D(filters,3,strides, padding='same', use_bias=False),\r\n",
    "            keras.layers.BatchNormalization(),\r\n",
    "            self.activation,\r\n",
    "            keras.layers.Conv2D(filters,3,1,padding='same', use_bias=False),\r\n",
    "            keras.layers.BatchNormalization(),\r\n",
    "        ]\r\n",
    "        self.skip_layers = []\r\n",
    "        if strides > 1:\r\n",
    "            self.skip_layers = [\r\n",
    "                keras.layers.Conv2D(filters,1, strides,padding='same', use_bias=False),\r\n",
    "                keras.layers.BatchNormalization()\r\n",
    "            ]\r\n",
    "def call(self, inputs):\r\n",
    "    Z = inputs\r\n",
    "    for layer in self.main_layers:\r\n",
    "        Z = layer(Z)\r\n",
    "        skip_Z = inputs\r\n",
    "    for layer in self.skip_layers:\r\n",
    "        skip_Z = layer(skip_Z)\r\n",
    "    return self.activation(Z + skip_Z)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "model = keras.models.Sequential()\r\n",
    "model.add(keras.layers.Conv2D(64,7,2,input_shape=[224,224,3],padding='same'))\r\n",
    "model.add(keras.layers.BatchNormalization())\r\n",
    "model.add(keras.layers.ReLU()),\r\n",
    "model.add(keras.layers.MaxPool2D(pool_size=3,strides=2,padding='same'))\r\n",
    "prev = 64\r\n",
    "for i in [64,64,64,128,128,128,128,256,256,256,256,512,512,512]:\r\n",
    "    strides = 1 if prev == i else 2\r\n",
    "    model.add(ResidualUnit(i,strides,keras.layers.ReLU()))\r\n",
    "    prev = i\r\n",
    "model.add(keras.layers.GlobalAvgPool2D())\r\n",
    "model.add(keras.layers.Flatten())   \r\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import tensorflow_datasets as tfds\r\n",
    "dataset, info = tfds.load(\"tf_flowers\", as_supervised=True, with_info=True)\r\n",
    "dataset_size = info.splits['train'].num_examples\r\n",
    "class_names = info.features['label'].names\r\n",
    "n_classes = info.features['label'].num_classes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "test_set_raw, valid_set_raw, train_set_raw = tfds.load(\r\n",
    "    \"tf_flowers\",\r\n",
    "    split=[\"train[:10%]\", \"train[10%:25%]\", \"train[25%:]\"],\r\n",
    "    as_supervised=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def preprocess(image,label):\r\n",
    "    resized_image = tf.image.resize(image, [224,224])\r\n",
    "    final_image = keras.applications.xception.preprocess_input(resized_image)\r\n",
    "    return final_image, label\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "train_set.shuffle(1000)\r\n",
    "train_set = train_set_raw.map(preprocess).batch(32).repeat().prefetch(1)\r\n",
    "valid_set = valid_set_raw.map(preprocess).batch(32).repeat().prefetch(1)\r\n",
    "test_set = test_set_raw.map(preprocess).batch(32).repeat().prefetch(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\r\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\r\n",
    "output = keras.layers.Dense(n_classes, activation='softmax')(avg)\r\n",
    "model = keras.Model(inputs=base_model.input, outputs=output)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "for layer in base_model.layers:\r\n",
    "    layer.trainable=False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.2, momentum=0.9, decay=0.01)\r\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer = optimizer, metrics=[\"accuracy\"])\r\n",
    "history = model.fit(train_set,steps_per_epoch=int(0.75 * dataset_size / 32), validation_data = valid_set,validation_steps=int(0.15 * dataset_size / 32), epochs=5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "86/86 [==============================] - 240s 3s/step - loss: 1.1728 - accuracy: 0.8045 - val_loss: 0.8381 - val_accuracy: 0.8382\n",
      "Epoch 2/5\n",
      " 5/86 [>.............................] - ETA: 3:01 - loss: 0.5420 - accuracy: 0.9125"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-7765223b70c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.75\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdataset_size\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.15\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdataset_size\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\r\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\r\n",
    "class_output = keras.layers.Dense(n_classes, activation='softmax')(avg)\r\n",
    "loc_output = keras.layers.Dense(4)(avg)\r\n",
    "model = keras.Model(inputs=base_model.input, outputs=[class_output, loc_output])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "model.compile(loss=[\"sparse_categorical_entropy\", \"mse\"], optimizer = optimizer, metrics=[\"accuracy\"])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1b532751c64f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sparse_categorical_entropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mse\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MNIST from scratch try Resnet Senet Fully convolutional net, pooling, lrn, etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "(X_train,y_train),(X_test,y_test) = keras.datasets.fashion_mnist.load_data()\r\n",
    "X_train = X_train.reshape(X_train.shape[0], 28,28,1).astype(np.float32)\r\n",
    "X_test = X_test.reshape(X_test.shape[0], 28,28,1).astype(np.float32)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "X_train = X_train/255\r\n",
    "X_test = X_test/255"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "model = keras.models.Sequential([\r\n",
    "    keras.layers.Conv2D(64,4,2,padding='same'),\r\n",
    "    keras.layers.BatchNormalization(),\r\n",
    "    keras.layers.ReLU(),\r\n",
    "    keras.layers.MaxPool2D(pool_size=3,strides=2,padding='same'),\r\n",
    "    ResidualUnit(64,1,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(64,1,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(64,1,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(128,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(128,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(128,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(128,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(256,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(256,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(256,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(512,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(512,2,keras.layers.ReLU()),\r\n",
    "    ResidualUnit(512,2,keras.layers.ReLU()),\r\n",
    "    keras.layers.GlobalAvgPool2D(),\r\n",
    "    keras.layers.Flatten(),\r\n",
    "    keras.layers.Dense(10,activation=\"softmax\")\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = keras.optimizers.Adam(learning_rate = 0.001), metrics = ['accuracy'])\r\n",
    "model.fit(X_train,y_train,epochs=1000,validation_data = (X_test,y_test),batch_size=32, steps_per_epoch=60000//32)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/1000\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 1.3116 - accuracy: 0.5717 - val_loss: 1.1445 - val_accuracy: 0.6024\n",
      "Epoch 2/1000\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.9911 - accuracy: 0.6685 - val_loss: 0.9925 - val_accuracy: 0.6314\n",
      "Epoch 3/1000\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.8891 - accuracy: 0.7029 - val_loss: 0.9893 - val_accuracy: 0.6490\n",
      "Epoch 4/1000\n",
      "1875/1875 [==============================] - 27s 15ms/step - loss: 0.8317 - accuracy: 0.7193 - val_loss: 0.8216 - val_accuracy: 0.7166\n",
      "Epoch 5/1000\n",
      "1875/1875 [==============================] - 27s 15ms/step - loss: 0.7942 - accuracy: 0.7329 - val_loss: 0.9803 - val_accuracy: 0.6543\n",
      "Epoch 6/1000\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.7673 - accuracy: 0.7374 - val_loss: 0.7799 - val_accuracy: 0.7215\n",
      "Epoch 7/1000\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.7487 - accuracy: 0.7452 - val_loss: 0.8538 - val_accuracy: 0.6904\n",
      "Epoch 8/1000\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.7311 - accuracy: 0.7485 - val_loss: 0.7765 - val_accuracy: 0.7281\n",
      "Epoch 9/1000\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.7203 - accuracy: 0.7540 - val_loss: 0.7411 - val_accuracy: 0.7390\n",
      "Epoch 10/1000\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.7066 - accuracy: 0.7567 - val_loss: 0.7980 - val_accuracy: 0.7145\n",
      "Epoch 11/1000\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.6941 - accuracy: 0.7612 - val_loss: 0.7596 - val_accuracy: 0.7369\n",
      "Epoch 12/1000\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.6858 - accuracy: 0.7630 - val_loss: 0.7238 - val_accuracy: 0.7523\n",
      "Epoch 13/1000\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.6784 - accuracy: 0.7649 - val_loss: 0.7785 - val_accuracy: 0.7315\n",
      "Epoch 14/1000\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.6712 - accuracy: 0.7694 - val_loss: 0.7405 - val_accuracy: 0.7397\n",
      "Epoch 15/1000\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.6651 - accuracy: 0.7683 - val_loss: 0.6937 - val_accuracy: 0.7575\n",
      "Epoch 16/1000\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.6569 - accuracy: 0.7725 - val_loss: 0.6899 - val_accuracy: 0.7534\n",
      "Epoch 17/1000\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.6529 - accuracy: 0.7731 - val_loss: 0.6503 - val_accuracy: 0.7718\n",
      "Epoch 18/1000\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.6454 - accuracy: 0.7769 - val_loss: 0.7091 - val_accuracy: 0.7526\n",
      "Epoch 19/1000\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.6436 - accuracy: 0.7750 - val_loss: 0.6577 - val_accuracy: 0.7752\n",
      "Epoch 20/1000\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.6375 - accuracy: 0.7773 - val_loss: 0.7308 - val_accuracy: 0.7475\n",
      "Epoch 21/1000\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.6344 - accuracy: 0.7793 - val_loss: 0.6444 - val_accuracy: 0.7765\n",
      "Epoch 22/1000\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.6274 - accuracy: 0.7810 - val_loss: 0.7233 - val_accuracy: 0.7452\n",
      "Epoch 23/1000\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.6255 - accuracy: 0.7814 - val_loss: 0.6954 - val_accuracy: 0.7581\n",
      "Epoch 24/1000\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.6250 - accuracy: 0.7818 - val_loss: 0.7587 - val_accuracy: 0.7331\n",
      "Epoch 25/1000\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.6180 - accuracy: 0.7841 - val_loss: 0.7223 - val_accuracy: 0.7463\n",
      "Epoch 26/1000\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.6142 - accuracy: 0.7849"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "464a224b326fd00042ecfc16c55fb6849077c393f04f27045b762af6d5e516e1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}