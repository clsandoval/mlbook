{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import urlextract\n",
    "import sklearn.model_selection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from zlib import crc32\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "import email\n",
    "import email.policy\n",
    "import re\n",
    "from html import unescape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"https://spamassassin.apache.org/old/publiccorpus/\"\n",
    "SPAM_PATH = os.path.join(\"datasets\", \"spam\")\n",
    "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\"\n",
    "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\"\n",
    "def fetch_spam_data(spam_url, ham_url, spam_path):\n",
    "    if not os.path.isdir(spam_path):\n",
    "        os.mkdir(spam_path)\n",
    "    for filename, url in ((\"ham.tar.bz2\", ham_url), (\"spam.tar.bz2\",spam_url)):\n",
    "        path = os.path.join(spam_path,filename)\n",
    "        if not os.path.isfile(path):\n",
    "            urllib.request.urlretrieve(url,path)\n",
    "        tar_bz2_file = tarfile.open(path)\n",
    "        tar_bz2_file.extractall(path=spam_path)\n",
    "        tar_bz2_file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_spam_data(SPAM_URL, HAM_URL, SPAM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "HAM_DIR = os.path.join(SPAM_PATH, \"easy_ham\")\n",
    "SPAM_DIR = os.path.join(SPAM_PATH, \"spam\")\n",
    "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 20]\n",
    "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emails(is_spam, filename, spam_path = SPAM_PATH):\n",
    "    directory = \"spam\" if is_spam else \"easy_ham\"\n",
    "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_emails = [load_emails(True, spam) for spam in spam_filenames]\n",
    "ham_emails = [load_emails(False, ham) for ham in ham_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ham_emails[1].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spam_emails[3].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(ham_emails + spam_emails, dtype=object)\n",
    "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,y,test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_to_plain_text(html):\n",
    "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
    "    return unescape(text)\n",
    "def get_email_structure(email):\n",
    "    if isinstance(email, str):\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload, list):\n",
    "        return \"multipart({})\".format(\", \".join([\n",
    "            get_email_structure(sub_email)\n",
    "            for sub_email in payload\n",
    "        ]))\n",
    "    else:\n",
    "        return email.get_content_type()\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures\n",
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\",\"text/html\"):\n",
    "            continue\n",
    "        try: \n",
    "            content = part.get_content()\n",
    "        except:\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_plain_text(html)\n",
    "class EmailWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers = True, lower_case = True,\n",
    "                 remove_punctuation = True, replace_urls=True,\n",
    "                 replace_numbers = True, stemming = True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "    def fit(self, X, y= None):\n",
    "        return self\n",
    "    def transform(self,X,y =None):\n",
    "        transformed_text = []\n",
    "        for email in X:\n",
    "            text = email_to_text(email) or \"\"\n",
    "            if self.lower_case: text = text.lower()\n",
    "            if self.replace_urls:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key = lambda url: len(url), reverse = True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \"URL\")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word,count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "                transformed_text.append(word_counts)\n",
    "            return np.array(transformed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures_counter(ham_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures_counter(spam_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_spam_emails = [email for email in train_x[train_y == 1] if get_email_structure(email) == \"text/html\"]\n",
    "sample_spam = html_spam_emails[7]\n",
    "print(sample_spam.get_content().strip()[:1000], \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(html_to_plain_text(sample_spam.get_content())[:1000], \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_email_text = [email_to_text(email) for email in train_x]\n",
    "print(train_email_text[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.PorterStemmer()\n",
    "url_extractor = urlextract.URLExtract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_transform = train_x[:10]\n",
    "sample_transform_wordcounts = EmailToWordCounterTransformer().fit_transform(sample_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_transform_wordcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-grocery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-central",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
